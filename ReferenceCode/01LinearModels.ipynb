{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Models\n",
    "- Linear RegressionÂ https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/readings/L02%20Linear%20Regression.pdf\n",
    "- Don't worry about the maths, the focus is on identifying the key results and implimenting them programmatically\n",
    "- This is not a linear algebra or calculus class, we will hack!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the regression problem in matrix form and then solve using normal equations. On the software side we will need to be able to have containers for \n",
    "\n",
    "- **Design Matrix: X**\n",
    "- **parameters/weights: $\\beta$** \n",
    "- **target variable: y**\n",
    "\n",
    "This is a good time to introduce a numerical computing framework, numpy. This let's us do linear algebra operations which are key to many ML/DL tasks. Also provides us with abstractions that can help us impliment results straight out of a textbook. On the downside numpy matrices can't use gpu, hence while working with neural networks we will need frameworks that do linear algebra and can be use gpu acceleration\n",
    "\n",
    "**What we need to code?**\n",
    "- The raw data will be present in flat files, we need to read that\n",
    "- Store them in to arrays\n",
    "- Create y, $\\beta$ and X\n",
    "- Solve for $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"data/regression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0        8.0         307.0       130.0  3504.0          12.0  70.0   \n",
       "1  15.0        8.0         350.0       165.0  3693.0          11.5  70.0   \n",
       "\n",
       "   origin  \n",
       "0     1.0  \n",
       "1     1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['mpg']\n",
    "X=data[['cylinders','displacement']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>302.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cylinders  displacement\n",
       "0        8.0         307.0\n",
       "1        8.0         350.0\n",
       "2        8.0         318.0\n",
       "3        8.0         304.0\n",
       "4        8.0         302.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['intercept']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[['intercept','cylinders','displacement']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the result 20, (https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/readings/L02%20Linear%20Regression.pdf), the parameters of the model are going to be:\n",
    "$\\beta=Inv((X^TX))X^Ty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X,y):\n",
    "    A=np.linalg.inv(np.matmul(np.transpose(X),X))\n",
    "    B=np.matmul(np.transpose(X),y)\n",
    "    return np.matmul(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.44476943, -0.51735734, -0.05225841])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have seen now is an example of closed form solution, very similar to saying that we have a formula to minimise the loss function. As we, progress further we will see that many times we may not be able to solve a loss minimization problem by finding a closed form solution. In such scenarios we can use a numerical procedure to calculate the minimum loss and the parameter values that result in such a loss value.\n",
    "\n",
    "One of the commonly used techniques is called gradient descent. First let's understand how gradient descent works using an example of a simple example of a polynomial minimization\n",
    "\n",
    "Assume I wanted to solve the following problem:\n",
    "**$argmin_x f(x) = x^2+4x+18$**\n",
    "\n",
    "The gradient descent algorithm works as below:\n",
    "$X_{new} := X_{old}-\\eta\\frac{d(f(x)}{d(x)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of function is 17.8416, value of gradient is 4, value of X is -0.04\n",
      "Value of function is 17.68947264, value of gradient is 3.92, value of X is -0.07919999999999999\n",
      "Value of function is 17.543369523456, value of gradient is 3.8416, value of X is -0.117616\n",
      "Value of function is 17.403052090327144, value of gradient is 3.764768, value of X is -0.15526368000000002\n",
      "Value of function is 17.268291227550186, value of gradient is 3.68947264, value of X is -0.1921584064\n"
     ]
    }
   ],
   "source": [
    "def grad(x):\n",
    "    return 2*x+4\n",
    "def f(x):\n",
    "    return x**2+4*x+18\n",
    "X=0\n",
    "eta=0.01\n",
    "for i in range(5):\n",
    "    gradient=grad(X)\n",
    "    Xnew=X-eta*gradient\n",
    "    X=Xnew\n",
    "    func=f(X)\n",
    "    print(f\"Value of function is {func}, value of gradient is {gradient}, value of X is {X}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent():\n",
    "    def __init__(self,grad,f):\n",
    "        self.grad=grad\n",
    "        self.f=f\n",
    "    def estimate(self,eta,n_iter,x_0):\n",
    "        x=x_0\n",
    "        for i in range(n_iter):\n",
    "            gradient=self.grad(x)\n",
    "            x_new=x-eta*gradient\n",
    "            x=x_new\n",
    "        result={'function_value':self.f(x),'parameter_value':x,'gradient_value':self.grad(x)}\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent=GradientDescent(grad,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_value': 14.0,\n",
       " 'parameter_value': -1.9999999966340651,\n",
       " 'gradient_value': 6.731869728326956e-09}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent.estimate(eta=0.01,n_iter=1000,x_0=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply gradient descent to solve the parameter estimation problem for linear regression, result 21 (https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/readings/L02%20Linear%20Regression.pdf) illustrates how this can be done:\n",
    "\n",
    "Gradient of RSS=$X^T(XW-y)$\n",
    "So, the update rule will be:\n",
    "- $W_{new}=W_{old}-\\eta X^T(XW_{old}-y)$\n",
    "\n",
    "Clearly we will need to initialize the $W$ matrix, we will do this initially by making all the entries as zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self,X,y):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.w=np.zeros((X.shape[1],))\n",
    "    def _gradient(self,X,W,y):\n",
    "        A=np.transpose(X)\n",
    "        B=np.matmul(X,W)-y\n",
    "        return np.matmul(A,B)\n",
    "    def _fit(self,n_iter,eta):\n",
    "        rss=[]\n",
    "        grads=[]\n",
    "        w=self.w\n",
    "        for i in range(n_iter):\n",
    "            iterations=i\n",
    "            grad=self._gradient(self.X,w,self.y)\n",
    "            w_new=w-(eta)*grad\n",
    "            w=w_new\n",
    "            rss.append(((np.matmul(X,w)-y)**2).mean())\n",
    "            grads.append(grad)\n",
    "            if i>2:\n",
    "                if abs(rss[i]-rss[i-1])<0.00000001:\n",
    "                    break\n",
    "        results={'parameters':w}\n",
    "        return results,rss,grads,iterations\n",
    "    def fit(self,n_iter,eta):\n",
    "        eta=np.array(eta)\n",
    "        results,rss,grads,iterations=self._fit(n_iter,eta)\n",
    "        self.results=results\n",
    "        self.rss=rss\n",
    "        self.grads=grads\n",
    "        self.iter=iterations\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['cylinders']].copy()\n",
    "X['intercept']=1\n",
    "X=X[['intercept','cylinders']]\n",
    "X=X.values\n",
    "y=data['mpg']\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=LinearRegression(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parameters': array([42.94792539, -3.56264961])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(n_iter=1000,eta=[0.001,0.0001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42.9493135 , -3.56288658])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11a852e90>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAXe0lEQVR4nO3df3Dc9X3n8edLliwZsGMby46xHQypoSFpKzid8R09LkASsP+IoZNmaFLitsyYNqSTzPSOmCZzTTt4Lrm5hInnWmoyUBxIQ2h+FE+AtmDIAB2ws6bG2LjGDnGMYtcSccB2jGVkve+P/QivpZW0klb67n71eszs7O5nvyu//LX12o8+3692FRGYmVm+NGQdwMzMqs/lbmaWQy53M7MccrmbmeWQy93MLIcasw4AMGfOnFi8eHHWMczM6srWrVtfj4jWco/VRLkvXryYQqGQdQwzs7oi6WeDPeZlGTOzHHK5m5nlkMvdzCyHXO5mZjnkcjczy6G6LvfOIyf4+Prn6Dx6IusoZmY1pa7Lfd2mPfx432HWPbEn6yhmZjVl2PPcJbUATwPNafvvRsRfSLoP+O/Am2nTP4iIbZIEfB1YARxP4y9UM/TFX3yM7p7ed+4/sHk/D2zeT3NjA7vvWF7NP8rMrC5VMnPvBq6OiN8C2oDrJC1Lj/3PiGhLl21pbDmwJF1WA3dVO/Qzt13FR9vOo6WpGL+lqYGVbefxzOevqvYfZWZWl4Yt9yg6lu42pctQn/CxEvhmet7zwExJ88ce9bS5M1qY3txId08vzY0NdPf0Mr25kbnTW6r5x5iZ1a2K1twlTZG0DegEHo+IzemhtZK2S7pTUnMaWwC8VvL0jjTW/2uullSQVOjq6hpx8NePdfPJy8/nB5++gk9efj5dx7pH/DXMzPJKI/mYPUkzgR8Afwr8AvgPYCpwN/CTiPgrSY8A/zsink3P2QTcFhFbB/u67e3t4feWMTMbGUlbI6K93GMjOlsmIt4AfgRcFxEH09JLN/B3wNK0WQewqORpC4EDI05tZmajNmy5S2pNM3YkTQM+BPx73zp6OjvmemBHespG4FMqWga8GREHxyW9mZmVVclb/s4HNkiaQvHF4KGI+KGkJyW1AgK2AX+ctn+U4mmQeymeCvmH1Y9tZmZDGbbcI2I7cGmZ8asH2T6AW8cezczMRquuf0PVzMzKc7mbmeWQy93MLIdc7mZmOeRyNzPLIZe7mVkOudzNzHLI5W5mlkMudzOzHHK5m5nlkMvdzCyHXO5mZjnkcjczyyGXu5lZDrnczcxyyOVuZpZDLnczsxxyuZuZ5ZDL3cwsh1zuZmY55HI3M8uhYctdUoukLZJelLRT0l+m8QskbZa0R9J3JE1N483p/t70+OLx/SuYmVl/lczcu4GrI+K3gDbgOknLgK8Ad0bEEuCXwM1p+5uBX0bErwF3pu3MzGwCDVvuUXQs3W1KlwCuBr6bxjcA16fbK9N90uPXSFLVEpuZ2bAqWnOXNEXSNqATeBz4CfBGRPSkTTqABen2AuA1gPT4m8C5Zb7makkFSYWurq6x/S3MzOwMFZV7RJyKiDZgIbAUeF+5zdJ1uVl6DBiIuDsi2iOivbW1tdK8ZmZWgRGdLRMRbwA/ApYBMyU1pocWAgfS7Q5gEUB6/F3A4WqENTOzylRytkyrpJnp9jTgQ8Au4CngY2mzVcDD6fbGdJ/0+JMRMWDmbmZm46dx+E2YD2yQNIXii8FDEfFDSS8DD0q6A/g34J60/T3A/ZL2Upyx3zgOuc3MbAjDlntEbAcuLTP+KsX19/7jJ4DfrUo6MzMbFf+GqplZDrnczcxyyOVuZpZDLnczsxxyuZuZ5ZDL3cwsh1zuZmY55HI3M8shl7uZWQ653M3McsjlbmaWQy53M7MccrmbmeWQy93MLIdc7mZmOeRyNzPLIZe7mVkOudzNzHLI5W5mlkMudzOzHHK5m5nl0LDlLmmRpKck7ZK0U9Jn0/iXJP1c0rZ0WVHynNsl7ZW0W9K14/kXMDOzgRor2KYH+LOIeEHSdGCrpMfTY3dGxP8t3VjSJcCNwPuB84AnJF0UEaeqGdzMzAY37Mw9Ig5GxAvp9lFgF7BgiKesBB6MiO6I+CmwF1hajbBmZlaZEa25S1oMXApsTkOfkbRd0r2SZqWxBcBrJU/roMyLgaTVkgqSCl1dXSMObmZmg6u43CWdA3wP+FxEHAHuAt4LtAEHga/2bVrm6TFgIOLuiGiPiPbW1tYRBzczs8FVVO6SmigW+7ci4vsAEXEoIk5FRC/wDU4vvXQAi0qevhA4UL3IZmY2nErOlhFwD7ArIr5WMj6/ZLMbgB3p9kbgRknNki4AlgBbqhfZzMyGU8nZMlcANwEvSdqWxv4c+D1JbRSXXPYBtwBExE5JDwEvUzzT5lafKWNmNrGGLfeIeJby6+iPDvGctcDaMeQyM7Mx8G+ompnlkMvdzCyH6r7cO4+c4OPrn6Pz6Imso5iZ1Yy6L/d1m/bw432HWffEnqyjmJnVjErOlqlJF3/xMbp7et+5/8Dm/TyweT/NjQ3svmN5hsnMzLJXtzP3Z267io+2nUdLU/Gv0NLUwMq283jm81dlnMzMLHt1W+5zZ7QwvbmR7p5emhsb6O7pZXpzI3Ont2Qdzcwsc3W7LAPw+rFuPnn5+Xxi6Xv4+y376fJBVTMzABQx4D29Jlx7e3sUCoWsY5iZ1RVJWyOivdxjdbssY2Zmg3O5m5nlkMvdzCyHXO5mZjnkcjczyyGXu5lZDrnczcxyyOVuZpZDLnczsxxyuZuZ5ZDL3cwsh1zuZmY5NGy5S1ok6SlJuyTtlPTZND5b0uOS9qTrWWlcktZJ2itpu6TLxvsvYWZmZ6pk5t4D/FlEvA9YBtwq6RJgDbApIpYAm9J9gOXAknRZDdxV9dRmZjakYcs9Ig5GxAvp9lFgF7AAWAlsSJttAK5Pt1cC34yi54GZkuZXPbmZmQ1qRGvukhYDlwKbgXkRcRCKLwDA3LTZAuC1kqd1pLH+X2u1pIKkQldX18iTm5nZoCoud0nnAN8DPhcRR4batMzYgE8EiYi7I6I9ItpbW1srjWFmZhWoqNwlNVEs9m9FxPfT8KG+5ZZ03ZnGO4BFJU9fCByoTlwzM6tEJWfLCLgH2BURXyt5aCOwKt1eBTxcMv6pdNbMMuDNvuUbMzObGJV8QPYVwE3AS5K2pbE/B74MPCTpZmA/8LvpsUeBFcBe4Djwh1VNbGZmwxq23CPiWcqvowNcU2b7AG4dYy4zMxsD/4aqmVkOudzNzHLI5W5mlkMudzOzHHK5m5nlkMvdzCyHXO5mZjmUi3LvPHKCj69/js6jJ7KOYmZWE3JR7us27eHH+w6z7ok9WUcxM6sJlbz9QM26+IuP0d3T+879Bzbv54HN+2lubGD3HcszTGZmlq26nrk/c9tVfLTtPFqain+NlqYGVradxzOfvyrjZGZm2arrcp87o4XpzY109/TS3NhAd08v05sbmTu9JetoZmaZqutlGYDXj3XzycvP5xNL38Pfb9lPlw+qmpmh4ps4Zqu9vT0KhULWMczM6oqkrRHRXu6xul6WMTOz8lzuZmY55HI3M8shl7uZWQ653M3McsjlbmaWQy53M7McGrbcJd0rqVPSjpKxL0n6uaRt6bKi5LHbJe2VtFvSteMV3MzMBlfJzP0+4Loy43dGRFu6PAog6RLgRuD96Tl/I2lKtcKamVllhi33iHgaOFzh11sJPBgR3RHxU2AvsHQM+czMbBTGsub+GUnb07LNrDS2AHitZJuONDaApNWSCpIKXV1dY4hR5A/sMDM7bbTlfhfwXqANOAh8NY2rzLZl37wmIu6OiPaIaG9tbR1ljNP8gR1mZqeN6l0hI+JQ321J3wB+mO52AItKNl0IHBh1ugr4AzvMzAYa1cxd0vySuzcAfWfSbARulNQs6QJgCbBlbBGH5g/sMDMbaNiZu6RvAx8E5kjqAP4C+KCkNopLLvuAWwAiYqekh4CXgR7g1og4NT7Ri/yBHWZmAw1b7hHxe2WG7xli+7XA2rGEGil/YIeZ2Zn8YR1mZnXKH9ZhZjbJuNzNzHIoV+XuX2QyMyvKVbn7F5nMzIpG9UtMtca/yGRmdqZczNz9i0xmZmfKRbn7F5nMzM6Ui2UZ8C8ymZmVyk25r7+peB5/55ETvHLoKP/vE5dmnMjMLDu5WJYp5TNmzMxyNHP3GTNmZqflZubuM2bMzE7LTbn7jBkzs9NysywDxTNmbrh0Aa/8x1EufvcMuo51Zx3JzCwTuZm5Q/GMmbOaprDz4BGmNTW8cwaNmdlkk5uZuw+ompmdlpuZe/8DqhJc+/55PqBqZpNSbsq99IBqgyACXu36lQ+omtmklJtyB/j2lv1EQG/65MA9ncdYvOYRLv7iY9kGMzObYLkq9+dvv8ZLM2ZmVFDuku6V1ClpR8nYbEmPS9qTrmelcUlaJ2mvpO2SLhvP8P15acbMrKiSmft9wHX9xtYAmyJiCbAp3QdYDixJl9XAXdWJWTkvzZiZVVDuEfE0cLjf8EpgQ7q9Abi+ZPybUfQ8MFPS/GqFrYSXZszMRr/mPi8iDgKk67lpfAHwWsl2HWlsAEmrJRUkFbq6ukYZYyAvzZiZVf+AqsqMRbkNI+LuiGiPiPbW1taqhvDSjJlNdqMt90N9yy3pujONdwCLSrZbCBwYfbzR6b80A7D43LO8NGNmk8Zoy30jsCrdXgU8XDL+qXTWzDLgzb7lm4k0d0YLP3zxACfePv12BPt+cZylazd59m5mk0Ilp0J+G3gOuFhSh6SbgS8DH5a0B/hwug/wKPAqsBf4BvDpcUldgSuXzGHxuWfR3OjZu5lNPooouyQ+odrb26NQKFT96154+yPvrLuX8puJmVkeSNoaEWXf/jZXv6HaX9/svaHkMK8/ncnMJoNcl/tzrx5m3y+OnzF7f3jbAf7bV57KLpSZ2QTIdbk/c9tVvPtdzUwpmbqfNXWKZ+5mlnu5Lve5M1roPNLNqZKp+/GTp3zWjJnlXq7LHXzWjJlNTrkv9/v+6HL2Hz5+xkfw+Zx3M8u73Jc7ePZuZpPPpCh3z97NbLKZFOUOnr2b2eQyacrds3czm0wmTblD+dn7wlnTPHs3s9yZVOVebvbe8cu3PHs3s9yZVOU+lOzfPs3MrHomXbk/f/s1LD73rDPGGgT/eOt/zSiRmVn1TbpynzujhX2/OH7GWG/Aiq8/y0VfeDSjVGZm1TXpyh3ggxfNKfthrydPhQvezHJhUpb7fX90OTdcuqDsYydPhQ+umlndm5TlDvCrkz1c0G/tvU93T68L3szq2qQt9/U3tXPRu6eXLfhr3z/P576bWV2btOUOxYL/2eHjA8b/eechfvvLT2aQyMysOiZ1uUPx1MhyfHDVzOrZmMpd0j5JL0naJqmQxmZLelzSnnQ9qzpRx8fcGS38zhAHVy9Y8widR09McCozs7Gpxsz9qohoi4j2dH8NsCkilgCb0v2aNtTB1QAuX7tpYgOZmY3ReCzLrAQ2pNsbgOvH4c+oqqEOrkKx4BevecRn0JhZ3RhruQfwL5K2SlqdxuZFxEGAdD233BMlrZZUkFTo6uoaY4yxG67gAXrD70BjZvVhrOV+RURcBiwHbpV0ZaVPjIi7I6I9ItpbW1vHGKM6hiv4t70Gb2Z1YkzlHhEH0nUn8ANgKXBI0nyAdN051pATqa/gpzWV3zUBLF27iZcPvjmxwczMRmDU5S7pbEnT+24DHwF2ABuBVWmzVcDDYw050dbf1M6VF7UOuUTjNxozs1o2lpn7POBZSS8CW4BHIuKfgC8DH5a0B/hwul93KlmDP3kqWOxlGjOrQYoaOEjY3t4ehUIh6xhl3XJ/gVe7fsWezmNDbnd28xT+4Y//C5fMf9cEJTOzyU7S1pLT0M8w6X9DdTjrb2rnwtazWTRrGmcNsg4P8KvuU6z4+rPc8Df/6pm8mWXOM/cRWLr2Cd56u4ejJ04Nu+0HFsygaUoD62/6T8yd3jIB6cxsshlq5u5yH6FKl2n6zJ7WxHmzp7nozazqXO5Vdsv9BV4+cARJ7C/zrpKDmTWtiROnTvGe2Wdx1tRGl72ZjYnLfZzccn+Bp1/pYorEsZPDL9X0d+7ZU5kzfSr7Dx934ZvZiLncx9loZ/LllM7um6YUD+C+faqXjl++5bNxzOwMLvcJ0lfyrx/r5q23e6v+9ZsbxZJ504Fi4ffN+EtfBCoZA3wMwCwHXO4TrK/kT57q5chbb3Oyp5dT2e/mAfoO9sLAF4GxvHiM95hzOEeecoxlouVyz1jf2jxAbxQ/gNvMrM/vX/4e7rjhN0b8PJd7jemb2Xce7aant5foBde9mTU3NrD7juUVbz9UuTdWLZVVbP1NA/8tPLs3m7waBB+5ZB5/df0HqvY1Xe41olzh9+m/ht93sLaBgTP+SsfMrHb0Bsw5p7mqJzi43OvAUMU/Uv1fKLp7eulNK3P9XwTG8uIx3mPO4Rx5yDGtqYEZLU1MbWyg61g31eRyn2Sq+UJhZrXL7wppZpZDLnczsxxyuZuZ5ZDL3cwsh1zuZmY55HI3M8uhmnj7AUldwM9G+fQ5wOtVjDNe6iFnPWSE+shZDxmhPnLWQ0bIJuf5EdFa7oGaKPexkFQY7L0Vakk95KyHjFAfOeshI9RHznrICLWX08syZmY55HI3M8uhPJT73VkHqFA95KyHjFAfOeshI9RHznrICDWWs+7X3M3MbKA8zNzNzKwfl7uZWQ7VdblLuk7Sbkl7Ja3JOk8fSfskvSRpm6RCGpst6XFJe9L1rAxy3SupU9KOkrGyuVS0Lu3b7ZIuyzDjlyT9PO3PbZJWlDx2e8q4W9K1E5Ex/bmLJD0laZeknZI+m8ZrZn8OkbGm9qekFklbJL2Ycv5lGr9A0ua0L78jaWoab07396bHF2eY8T5JPy3Zl21pPJPvnzNERF1egCnAT4ALganAi8AlWedK2fYBc/qN/R9gTbq9BvhKBrmuBC4DdgyXC1gBPAYIWAZszjDjl4D/UWbbS9K/ezNwQfr/MGWCcs4HLku3pwOvpDw1sz+HyFhT+zPtk3PS7SZgc9pHDwE3pvG/Bf4k3f408Lfp9o3AdzLMeB/wsTLbZ/L9U3qp55n7UmBvRLwaESeBB4GVGWcaykpgQ7q9Abh+ogNExNPA4X7Dg+VaCXwzip4HZkqan1HGwawEHoyI7oj4KbCX4v+LcRcRByPihXT7KLALWEAN7c8hMg4mk/2Z9smxdLcpXQK4GvhuGu+/L/v28XeBayQpo4yDyeT7p1Q9l/sC4LWS+x0M/R93IgXwL5K2SlqdxuZFxEEoftMBczNLd6bBctXa/v1M+vH23pIlrZrImJYFLqU4m6vJ/dkvI9TY/pQ0RdI2oBN4nOJPDW9ERE+ZLO/kTI+/CZw70Rkjom9frk378k5Jzf0zlsk/Ieq53Mu9UtfKeZ1XRMRlwHLgVklXZh1oFGpp/94FvBdoAw4CX03jmWeUdA7wPeBzEXFkqE3LjE1I1jIZa25/RsSpiGgDFlL8aeF9Q2TJJGf/jJI+ANwO/Drwn4HZwOezzFiqnsu9A1hUcn8hcCCjLGeIiAPpuhP4AcX/rIf6fixL153ZJTzDYLlqZv9GxKH0jdULfIPTSwWZZpTURLE0vxUR30/DNbU/y2Ws1f2Zsr0B/IjiOvVMSX2f81ya5Z2c6fF3UflSXjUzXpeWviIiuoG/o4b2ZT2X+4+BJemI+lSKB1Y2ZpwJSWdLmt53G/gIsINitlVps1XAw9kkHGCwXBuBT6Wj/suAN/uWGyZav7XKGyjuTyhmvDGdPXEBsATYMkGZBNwD7IqIr5U8VDP7c7CMtbY/JbVKmpluTwM+RPH4wFPAx9Jm/fdl3z7+GPBkpKOYE5zx30teyEXxmEDpvsz2+2eij+BW80LxiPQrFNfnvpB1npTpQopnHLwI7OzLRXFNcBOwJ13PziDbtyn+GP42xZnFzYPlovhj5V+nffsS0J5hxvtThu0Uv2nml2z/hZRxN7B8Avflb1P8MXs7sC1dVtTS/hwiY03tT+A3gX9LeXYA/yuNX0jxxWUv8A9AcxpvSff3pscvzDDjk2lf7gAe4PQZNZl8/5Re/PYDZmY5VM/LMmZmNgiXu5lZDrnczcxyyOVuZpZDLnczsxxyuZuZ5ZDL3cwsh/4/tta6kRav7c4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(reg.iter+1),reg.rss,\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can obtain predictions and get a sense of model performance by using the wights learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_linear(X,w):\n",
    "    return np.matmul(X,w)\n",
    "preds=predict_linear(X,reg.fit(n_iter=1000,eta=[0.001,0.0001])['parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.55327152,  -0.55327152,  -3.55327152,  -1.55327152,\n",
       "        -2.55327152,  -0.55327152,   0.44672848,   0.44672848,\n",
       "         0.44672848,  -0.55327152,  -0.55327152,   0.44672848,\n",
       "        -0.55327152,   0.44672848,   4.69732693,  -0.4279723 ,\n",
       "         3.5720277 ,   0.5720277 ,   1.69732693,   2.69732693,\n",
       "         3.69732693,   4.69732693,   3.69732693,   2.69732693,\n",
       "         0.5720277 ,   4.44672848,   4.44672848,   3.44672848,\n",
       "         5.44672848,   1.69732693,   0.69732693,   3.69732693,\n",
       "         3.69732693,   2.5720277 ,   5.5720277 ,   4.5720277 ,\n",
       "         2.5720277 ,   3.5720277 ,   0.44672848,   0.44672848,\n",
       "         0.44672848,   0.44672848,   2.44672848,   1.44672848,\n",
       "         1.44672848,   3.5720277 ,   6.69732693,   2.5720277 ,\n",
       "         3.5720277 ,   5.69732693,   0.69732693,  -1.30267307,\n",
       "        -1.30267307,  -2.30267307,  -6.30267307,   1.69732693,\n",
       "         2.69732693,   4.69732693,   3.69732693,   5.69732693,\n",
       "         8.69732693,   7.69732693,   1.44672848,   0.44672848,\n",
       "        -0.55327152,   0.44672848,  -2.55327152,   3.44672848,\n",
       "         1.44672848,   2.44672848,   1.44672848,  13.25997655,\n",
       "        -0.55327152,   1.44672848,   1.44672848,   0.44672848,\n",
       "        10.69732693,   6.69732693,   7.69732693,   2.69732693,\n",
       "         6.69732693,   0.69732693,   5.69732693,   0.69732693,\n",
       "         1.69732693,   1.44672848,   0.44672848,   1.44672848,\n",
       "         0.44672848,  -0.55327152,   2.44672848,   1.44672848,\n",
       "         1.44672848,   0.44672848,   1.44672848,   2.44672848,\n",
       "         1.44672848,   3.5720277 ,   5.5720277 ,   3.5720277 ,\n",
       "         3.5720277 ,  -1.4279723 ,   2.69732693,   3.44672848,\n",
       "         2.44672848,   1.44672848,   2.44672848,   3.5720277 ,\n",
       "         8.69732693,   7.69732693,   6.69732693,  14.25997655,\n",
       "         9.69732693,   0.5720277 ,   2.69732693,  -0.55327152,\n",
       "        -1.55327152,  -0.30267307,   4.69732693,   8.69732693,\n",
       "         9.69732693,  -0.55327152,   4.69732693,   1.5720277 ,\n",
       "         3.44672848,   1.5720277 ,   0.5720277 ,   2.5720277 ,\n",
       "         6.5720277 ,  -2.30267307,   2.69732693,  -3.30267307,\n",
       "         3.69732693,   5.5720277 ,   5.5720277 ,   3.5720277 ,\n",
       "        -1.55327152,   1.44672848,   0.44672848,   0.44672848,\n",
       "         0.44672848,  -0.30267307,   2.69732693,   2.69732693,\n",
       "        -2.30267307,  -3.30267307,   0.69732693,   4.69732693,\n",
       "         2.69732693,   4.69732693,   2.69732693,  -2.30267307,\n",
       "         2.5720277 ,   3.5720277 ,   6.5720277 ,   6.5720277 ,\n",
       "        -1.55327152,  -0.55327152,  -1.55327152,   0.44672848,\n",
       "         4.5720277 ,   5.5720277 ,   6.5720277 ,   3.5720277 ,\n",
       "         0.5720277 ,  -5.55327152,   1.44672848,  -0.30267307,\n",
       "         5.69732693,   1.5720277 ,   5.69732693,   4.69732693,\n",
       "         3.69732693,   4.69732693,   3.5720277 ,  -0.30267307,\n",
       "         2.5720277 ,   5.69732693,   5.69732693,   6.69732693,\n",
       "         3.69732693,  -4.30267307,   0.69732693,   3.69732693,\n",
       "         3.69732693,   2.69732693,   1.69732693,  -3.05327152,\n",
       "        -1.55327152,  -1.05327152,  -0.05327152,  -0.4279723 ,\n",
       "        -0.4279723 ,  -2.4279723 ,  -0.9279723 ,  -0.30267307,\n",
       "         4.19732693,  -0.30267307,  -4.30267307,   1.5720277 ,\n",
       "         3.5720277 ,   3.0720277 ,   4.0720277 ,  -0.80267307,\n",
       "        -3.30267307,   0.69732693,   2.19732693,   8.69732693,\n",
       "         1.44672848,   9.69732693,   2.5720277 ,   5.0720277 ,\n",
       "        -2.05327152,   1.44672848,   1.44672848,   1.44672848,\n",
       "        -2.80267307,  -1.30267307,  -7.30267307,   3.19732693,\n",
       "        -4.80267307,  -3.05327152,  -2.55327152,  -1.05327152,\n",
       "        -0.55327152,   4.0720277 ,   1.0720277 ,   2.5720277 ,\n",
       "         3.0720277 ,  -1.55327152,  -1.05327152,  -1.05327152,\n",
       "        -1.55327152,  -0.30267307,   4.19732693,   2.69732693,\n",
       "         3.19732693,  -1.80267307,  -4.80267307,  -1.30267307,\n",
       "        -1.80267307,  -0.4279723 ,   7.19732693,  10.75997655,\n",
       "       -14.40267307,  -7.40267307,  -4.10267307, -10.70267307,\n",
       "        -7.40267307,  -5.45327152,  -4.95327152,  -5.75327152,\n",
       "         2.3720277 ,   1.0720277 ,   1.3720277 ,   3.59732693,\n",
       "         1.0720277 ,   2.1720277 ,   0.9720277 ,   0.7720277 ,\n",
       "         2.9720277 ,   3.4720277 ,  -4.75327152,   3.8720277 ,\n",
       "        -3.65327152,  -3.05327152,  -1.30267307,   1.19732693,\n",
       "         1.49732693,  -2.20267307,   7.59732693,   5.49732693,\n",
       "         4.89732693,   4.79732693,   4.83467732,   4.5720277 ,\n",
       "         7.09732693,   5.3720277 ,  -2.80267307,  -0.80267307,\n",
       "         0.0720277 ,   1.7720277 ,   6.39732693,   1.3720277 ,\n",
       "         0.9720277 ,  -2.55327152,  -3.15327152,  -2.05327152,\n",
       "        -3.75327152,  -2.45327152,  -1.05327152,  -4.75327152,\n",
       "        -4.05327152,  -3.20267307,  -5.40267307,  -7.00267307,\n",
       "         1.29732693,  -0.26532268,  -8.55327152,   1.49732693,\n",
       "        -9.45327152,  -5.50267307,  -5.80267307,  -3.10267307,\n",
       "        -8.60267307,   0.29732693,  -7.2279723 ,  -5.2279723 ,\n",
       "        -4.80267307, -12.80267307,  -9.40267307,  -3.40267307,\n",
       "        -8.50267307,   0.69732693,   2.29732693,   4.39732693,\n",
       "         2.4720277 ,  -5.60267307,  -1.10267307,  -2.60267307,\n",
       "        -8.30267307,  -3.50267307, -17.90267307,   0.79732693,\n",
       "       -12.10267307, -15.60267307, -14.70267307, -11.26532268,\n",
       "        -1.30267307, -15.90267307, -12.20267307,  -5.10267307,\n",
       "        -1.10267307, -11.1279723 ,   8.55997655,  -6.30267307,\n",
       "         5.09732693,  -3.70267307,   1.49732693,   2.09732693,\n",
       "         2.89732693,  -1.9279723 ,  -1.30267307, -10.40267307,\n",
       "       -10.30267307,  -6.40267307,  -3.60267307,  -8.30267307,\n",
       "        -9.00267307,  -5.40267307,  -6.00267307,  -5.70267307,\n",
       "        -1.20267307,  -4.30267307,  -5.80267307,  -5.00267307,\n",
       "        -3.70267307,  -4.20267307,  -2.90267307,   0.59732693,\n",
       "        -9.1279723 ,  -3.8279723 ,  -2.6279723 ,  -0.8279723 ,\n",
       "       -12.15327152,   1.3720277 ,   3.9720277 ,   0.69732693,\n",
       "         1.69732693,  -5.30267307,  -2.30267307,  -0.30267307,\n",
       "         1.69732693,   4.69732693,   5.69732693,  -7.30267307,\n",
       "        -8.30267307,  -2.30267307,  -9.30267307,  -7.30267307,\n",
       "        -7.30267307,  -7.30267307,  -5.30267307,  -9.30267307,\n",
       "        -3.30267307,  -9.30267307,  -3.4279723 , -16.4279723 ,\n",
       "         2.69732693,  -0.4279723 ,  -3.30267307,  -7.30267307,\n",
       "         1.69732693,   1.69732693, -15.30267307,  -3.30267307,\n",
       "         0.69732693,  -2.30267307])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds-y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier\n",
    "- Undrestand log-loss (https://web.stanford.edu/~jurafsky/slp3/5.pdf)\n",
    "- Build a simple class that can minimize log-loss for a linear classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function of logistic regression is $-[ylog(p)+(1-y)log(1-p)]$, refer to result 5.9 (https://web.stanford.edu/~jurafsky/slp3/5.pdf)\n",
    "\n",
    "The gradient for the loss function is: $X^T(P-y)=X^T(\\sigma(XW)-y)$\n",
    "\n",
    "Finally the gradient update will be:\n",
    "- $W_{new}=W_{old}-\\eta X^T(\\sigma(XW)-y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self,X,y):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.w=np.zeros((self.X.shape[1],))\n",
    "    def _gradient(self,X,w,y):\n",
    "        z=np.matmul(X,w)\n",
    "        sigma=1/(1+np.exp(-z))\n",
    "        A=np.transpose(X)\n",
    "        B=sigma-y\n",
    "        return np.matmul(A,B)\n",
    "    def loss(self,X,w,y):\n",
    "        delta=0.000001\n",
    "        z=np.matmul(X,w)\n",
    "        p=1/(1+np.exp(-z))\n",
    "        l=(-(np.log(p+delta)*y+(1-y)*np.log(1-p+delta))).mean()\n",
    "        return l\n",
    "    def _fit(self,n_iter,eta):\n",
    "        logloss=[]\n",
    "        w=self.w\n",
    "        for i in range(n_iter):\n",
    "            iterations=i\n",
    "            grad=self._gradient(self.X,w,self.y)\n",
    "            w_new=w-eta*grad\n",
    "            w=w_new\n",
    "            logloss.append(self.loss(self.X,w,self.y))\n",
    "            if i>2:\n",
    "                if abs(logloss[i]-logloss[i-1])<0.0000000001:\n",
    "                    break\n",
    "        results={'parameters':w}\n",
    "        return results,iterations,logloss\n",
    "    def fit(self,n_iter,eta):\n",
    "        eta=np.array(eta)\n",
    "        results,iterations,logloss=self._fit(n_iter,eta)\n",
    "        self.iter=iterations\n",
    "        self.logloss=logloss\n",
    "        self.results=results\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_pregnant</th>\n",
       "      <th>Plasma_glucose</th>\n",
       "      <th>Blood_pres</th>\n",
       "      <th>Skin_thick</th>\n",
       "      <th>Serum_insu</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes_func</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No_pregnant  Plasma_glucose  Blood_pres  Skin_thick  Serum_insu   BMI  \\\n",
       "0            6             148          72          35           0  33.6   \n",
       "1            1              85          66          29           0  26.6   \n",
       "\n",
       "   Diabetes_func  Age  Class  \n",
       "0          0.627   50      1  \n",
       "1          0.351   31      0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"data/classification.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['No_pregnant']].copy()\n",
    "X['intercept']=1\n",
    "X=X[['intercept','No_pregnant']]\n",
    "y=data['Class']\n",
    "X=X.values\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parameters': array([-1.17658058,  0.13716497])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(n_iter=1000,eta=[0.01,0.0001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11a90b550>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(clf.iter+1),clf.logloss,\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual parameter estimates beta=-1.17675,beta1=0.13716 using a standard implimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we estimate parameters, of a model we may want to understand how good or bad a job we are doing at making predictions. We can get probability estimates from the model and try to find:\n",
    "- Accuracy\n",
    "- Confusion Matrix\n",
    "- AUC\n",
    "\n",
    "We will first create an inference function, we will use the computed weights and make preidctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,w):\n",
    "    z=np.matmul(X,w)\n",
    "    probs=1/(1+np.exp(-z))\n",
    "    return probs\n",
    "p=predict(X,clf.results['parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6640625"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_labels=pd.Series(p).map(lambda x:1 if x>0.5 else 0)\n",
    "(p_labels.values==y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[462,  38],\n",
       "       [220,  48]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,roc_auc_score\n",
    "confusion_matrix(y,p_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6195149253731344"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as linear classifiers are concerned, we may want to extend them to be able to do multiclass, classification. We can do this by making changes to the:\n",
    "- Logistic Function, make it more generalizable\n",
    "- Logitsic Cost Functon,make it more generalizable\n",
    "\n",
    "Instead of using logistic function, we use softmax function to give probability score for each class (5.31, https://web.stanford.edu/~jurafsky/slp3/5.pdf ). To compute the loss, cross entropy loss is used (5.32, https://web.stanford.edu/~jurafsky/slp3/5.pdf)\n",
    "\n",
    "The matrix formulation for this will be $X\\times W$, where $X$ will be $r\\times m$ and $W$ will be $m\\times k$, where:\n",
    "- r, number of rows in the predictor matrix\n",
    "- m, number of predictors in the model\n",
    "- k, number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([[1,0.2],[1,0.3],[1,0.4]])\n",
    "y=np.array([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0.2],\n",
       "       [1. , 0.3],\n",
       "       [1. , 0.4]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X,y):\n",
    "    n_class=len(set(y))\n",
    "    w=np.ones((X.shape[1],n_class))\n",
    "    z=np.matmul(X,w)\n",
    "    e_z=np.exp(z)\n",
    "    return e_z/e_z.sum(axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.33333333, 0.33333333])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(X,y)[range(y.shape[0]),y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(softmax,y):\n",
    "    loss=-np.log(softmax[range(y.shape[0]),y])\n",
    "    loss=np.sum(loss)/y.shape[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0986122886681098"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(softmax(X,y),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
